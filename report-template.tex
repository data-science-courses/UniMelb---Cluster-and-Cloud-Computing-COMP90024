\documentclass[11pt]{article}
\usepackage{colacl}
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}}
\usepackage{pgfplots}
\pgfplotsset{width=6.5cm,compat=2.0}
\sloppy

\title{Cluster and Cloud Computing - HPC Twitter Processing}
\author{Adam Mooy, Vinh Nguyen}

\begin{document}
\maketitle

\section{Objective}

The goal of this assignment is to implement a simple, parallelise application leveraging the University of Melbourne HPC facility SPARTAN. The application will be used on a large Twitter data set to identify the top 10 most commonly used hashtags and most commonly used languages. 

\section{Twitter Data Set}
The big twitter dataset comes in JSON format and has 4057522 rows of tweets from Sydney with a size of 19.34 GB. Every Tweet JSON includes an entities section which provides metadata such as hashtags and language. We decided to extract and count this readily available metadata. 

\section{Application details}
\subsection{Python script}
Our program makes use of the method os.path.getsize(). It returns the size of the specified file in bytes. With this number, we are able to calculate the start and end byte positions for each rank.  Each rank will get its evenly distributed chunk of the file start and end position with following equations \[start =  \frac{rank \times filesize}{number of processes} \] \[end =  \frac{(rank+1) \times filesize}{number of processes} \]. 

All processes read its chunk line by line. To extract the hashtags and languages, all unwanted trailing characters like ',' ']'  are removed. The processes will extract lowercased ["hashtags"] and ["lang"] from the ["doc"] entities. Using Python Counters class, the frequencies of each hashtag and language is updated. Each process has its counts for hashtags and languages. These counts gather at Rank 0, where Rank 0 sum the counts and return the top 10 most common hashtags and languages. 

\subsection{Slurm script}

Only one Slurm script is created, the user only needs to set the following parameters: nodes, ntasks, time, file and script in UNIX to require resources accordingly. Theoretically, Cloud nodes are comparatively slower, especially on multiple node jobs because the communication between Cloud nodes is slower than Physical nodes. In contrast, Physical nodes are connected by high-speed 25Gb networking with 1.15 µsec latency which is preferable for multi-node jobs. When experimenting on small and tiny twitter files, Cloud partition execution time is faster than Physical partition. The reason could be the traffic wasn't that bad; therefore, it has lower latency and outperforms Physical nodes.  However, since both small and tiny Twitter file sizes are relatively small compared to big Twitter, Physical partition is used when running application on the big Twitter file. In order to have a proper comparison, Intel(R) Xeon(R) Gold 6154 CPU @ 3.00GHz nodes were used. 

\section{Results}

\begin{tikzpicture}
\begin{axis}[
    ybar,
    enlargelimits=0.15,
    legend style={at={(0.5,-0.15)},
      anchor=north,legend columns=-1},
    ylabel={Time(s)},
    symbolic x coords={1N1C,1N8C,2N8C},
    xtick=data,
    nodes near coords,
    nodes near coords align={vertical},
    ]
\addplot coordinates {(1N1C,817.306) (1N8C,103.585) (2N8C,105.09)};
\end{axis}
\end{tikzpicture}

These results are obtained from attached 1n1c-bigTwitter.json-15909060.out 1n8c-bigTwitter.json-15909058.out and 2n8c-bigTwitter.json-15909059.out slurm outputs.

\begin{table}[h]
 \begin{center}
\begin{tabular}{|l|l|l|l|l|}

      \hline
      Rank &1N1C & 1N8C & 2N8C  \\
      \hline\hline
      0 & 816.78 & 100.43 & 102.29 \\
      1 & - & 100.32 & 102.18 \\
      2 & - & 100.32 & 102.18 \\
      3 & - & 100.32 & 102.18 \\
      4 & - & 100.32 & 102.18 \\
      5 & - & 100.32 & 102.18 \\
      6 & - & 100.32 & 102.18 \\
      7 & - & 100.32 & 102.18 \\

     \hline

\end{tabular}
\caption{Top 10 most common languages}\label{table2}
 \end{center}
\end{table}

\section{Discussion}

Figure 1 shows the time spent to run the application under different resources. As expected the amount of time to run the application using 8 cores would be quicker than single-core. 2 Nodes 8 Cores is slightly slower than 1 Node 8 Cores because there is a communication time between 2 Nodes. 

From Table 1, execution time on each cores were recorded to ensure tasks were evenly distributed among all processes. Rank 0 took slightly longer as it has to gather all the counts from each processes and computed the total count. 

\section{Conclusion}



\section{INCLUDE OR NOT}

\begin{table}[h]
 \begin{center}
\begin{tabular}{|l|l|l|l|l|}

      \hline
      Rank &Hashtags & Counts   \\
      \hline\hline
      1 & auspol & 19878 \\
      2 & coronavirus & 10110 \\
      3 & มาพ่องเพิ่งอะไระไร & 7531 \\
      4 & firefightaustralia & 6812 \\
      5 & oldme & 6418 \\
      6 & sydney & 6196 \\
      7 & scottyfrommarketing & 5185\\
      8 & grammys & 5085 \\
      9 & assange & 4689 \\
      10 & sportsrorts & 4516 \\
    
     \hline

\end{tabular}
\caption{Top 10 most common hashtags}\label{table1}
 \end{center}
\end{table}


\begin{table}[h]
 \begin{center}
\begin{tabular}{|l|l|l|l|l|}

      \hline
      Rank &Languages & Counts   \\
      \hline\hline
      1 & English (en) & 3107115 \\
      2 & Undefined (un) & 252117 \\
      3 & Thai (th) & 134571 \\
      4 & Portuguese (pt) & 125858 \\
      5 & Spanish (es) & 74028 \\
      6 & Japanese (ja) & 49929 \\
      7 & Tagalog (tl) & 44560\\
      8 & Indonesian (in) & 42296 \\
      9 & French (fr) & 38098 \\
      10 & Arabic (ar) & 24501 \\
    
     \hline

\end{tabular}
\caption{Top 10 most common languages}\label{table2}
 \end{center}
\end{table}



\end{document}
